{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kan import KAN, LBFGS\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import autograd\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "  dev = \"cuda:0\"\n",
    "else:\n",
    "  dev = \"cpu\"\n",
    "device = torch.device(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_b       = 10.0\n",
    "lambda_ic      =10.0\n",
    "\n",
    "steps = 20\n",
    "alpha = 0.1\n",
    "log = 1\n",
    "\n",
    "global loss_int_hist, loss_bc_hist, loss_ic_hist, pred_hist, xdim\n",
    "\n",
    "N = 50\n",
    "xdim = 3\n",
    "pred_hist      = np.zeros(N)\n",
    "\n",
    "model_shape = [xdim+1, 10, 10, 1]\n",
    "\n",
    "model = KAN(width=model_shape, grid=5, k=3, grid_eps=1.0, noise_scale_base=0.25, device=device)\n",
    "optimizer = LBFGS(model.parameters(), lr=1, history_size=10, line_search_fn=\"strong_wolfe\", tolerance_grad=1e-32, tolerance_change=1e-32, tolerance_ys=1e-32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fun(x_int, x_bc, model):\n",
    "    mu = 1\n",
    "    \n",
    "    x_int = x_int.to(device)\n",
    "    x_bc = x_bc.to(device)\n",
    "    \n",
    "    x, t = x_int[:, :-1], x_int[:, -1:]\n",
    "    x = x.to(device)\n",
    "    t = t.to(device)\n",
    "    t.requires_grad_()\n",
    "    x.requires_grad_()\n",
    "\n",
    "    # Combine x and t to create input tensor for the model\n",
    "    input_tensor = torch.cat((x, t), dim=1).to(device)\n",
    "    u = model(input_tensor).to(device)\n",
    "\n",
    "    def model_output(u):\n",
    "        return u\n",
    "\n",
    "    # Initialize tensors for derivatives\n",
    "    du_dt = torch.zeros_like(u, device=device)\n",
    "    du_dx = torch.zeros_like(x, device=device)\n",
    "    d2u_dx2 = torch.zeros_like(x, device=device)\n",
    "\n",
    "    # First-order time derivative\n",
    "    du_dt = torch.autograd.grad(u, t, grad_outputs=torch.ones_like(t, device=device), create_graph=True)[0]\n",
    "    \n",
    "    # First-order spatial derivative\n",
    "    du_dx = torch.autograd.grad(u, x, grad_outputs=torch.ones_like(u, device=device), retain_graph=True, allow_unused=True)[0]\n",
    "\n",
    "    # Second-order spatial derivative    \n",
    "    d2u_dx2 = torch.autograd.functional.jacobian(lambda x: du_dx.sum(), x)\n",
    "\n",
    "\n",
    "    # Compute the residual R_int\n",
    "    R_int = torch.mean((du_dt.squeeze(1) + torch.sum(d2u_dx2, dim=1) - mu * torch.sum(du_dx ** 2, dim=1)) ** 2)\n",
    "\n",
    "    # Boundary condition handling\n",
    "    x_bc, t_bc = x_bc[:, :-1], x_bc[:, -1:]\n",
    "    x_bc = x_bc.to(device)\n",
    "    t_bc = t_bc.to(device)\n",
    "    \n",
    "    t_bc.requires_grad_()\n",
    "    input_tensor_bc = torch.cat((x_bc, t_bc), dim=1).to(device)\n",
    "    u_bc = model(input_tensor_bc)\n",
    "\n",
    "    R_bc = torch.mean(torch.square(u_bc - torch.log((1 + torch.norm(x_bc, p=2) ** 2) / 2)))\n",
    "\n",
    "    return R_int, R_bc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    global T\n",
    "    T = 1\n",
    "\n",
    "    tensor1 = torch.randn((50, xdim), device=device)\n",
    "    tensor2 = torch.rand((50, 1), device=device)*T\n",
    "    x_int = torch.cat([tensor1, tensor2], dim=1)\n",
    "    \n",
    "    tensor1 = torch.randn((50, xdim), device=device)\n",
    "    tensor2 = torch.ones((50, 1), device=device)*T\n",
    "    x_bc = torch.cat([tensor1, tensor2], dim=1)\n",
    "    \n",
    "    return x_int, x_bc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(steps):\n",
    "\n",
    "    loss_int_hist  = np.zeros(steps)\n",
    "    loss_bc_hist    = np.zeros(steps)\n",
    "    # loss_ic_hist    = np.zeros(steps)\n",
    "    \n",
    "    pbar = tqdm(range(steps), desc='description')\n",
    "    # optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-7)\n",
    "\n",
    "    for epoch in pbar:\n",
    "        def closure():\n",
    "            global loss_int, loss_bc, x_int\n",
    "            # zero the gradient buffers\n",
    "            optimizer.zero_grad()\n",
    "            x_int, x_bc = get_data()\n",
    "            x_int = x_int.to(device)\n",
    "            x_bc = x_bc.to(device)\n",
    "\n",
    "            # x_int = x_int.reshape(-1, 1)\n",
    "            # x_bc = x_bc.reshape(-1, 1)\n",
    "            \n",
    "            # print(x_int.shape)\n",
    "            # print(x_bc.shape)\n",
    "\n",
    "            # compute losses\n",
    "            loss_int, loss_bc = loss_fun(x_int, x_bc, model)\n",
    "            loss = lambda_ic*loss_int + lambda_b*loss_bc\n",
    "\n",
    "            # compute gradients of training loss\n",
    "            loss.backward()\n",
    "            \n",
    "            return loss\n",
    "        \n",
    "        x_int, x_bc = get_data()\n",
    "        # print(x_int.shape)\n",
    "        # print(x_bc.shape)\n",
    "\n",
    "#         if epoch % 5 == 0 and epoch < 50:\n",
    "#             model.update_grid_from_samples(x_int)\n",
    "\n",
    "        optimizer.step(closure)\n",
    "        loss = loss_int + lambda_b*loss_bc\n",
    "\n",
    "        if epoch % log == 0:\n",
    "            pbar.set_description(\"interior pde loss: %.2e | bc loss: %.2e \" % (loss_int.cpu().detach().numpy(), loss_bc.cpu().detach().numpy()))\n",
    "        # print(f'   --- epoch {epoch+1}: loss_int = {loss_int.item():.4e}, loss_bc = {loss_bc.item():.4e}, loss_ic = {loss_ic.item():.4e}')\n",
    "        \n",
    "        # save loss\n",
    "        loss_int_hist[epoch] = loss_int\n",
    "        loss_bc_hist[epoch] = loss_bc\n",
    "\n",
    "    return loss_int_hist, loss_bc_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "description:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "interior pde loss: 3.39e-02 | bc loss: 8.06e-02 : 100%|██████████| 20/20 [00:42<00:00,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed in 42.29 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Measure execution time\n",
    "start_time = time.time()\n",
    "\n",
    "int_losses, bc_losses = train(steps)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Training completed in {elapsed_time:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_seconds(seconds):\n",
    "    minutes = seconds // 60\n",
    "    remaining_seconds = seconds % 60\n",
    "    return f\"{minutes} mins {remaining_seconds} secs\"\n",
    "\n",
    "formatted_time = convert_seconds(elapsed_time)\n",
    "\n",
    "data = {\n",
    "    \"Model Shape\": model_shape,\n",
    "    \"Input Dimension\": xdim,\n",
    "    \"Epochs/Steps\": steps,\n",
    "    \"Final Interior PDE Loss\": int_losses[-1],\n",
    "    \"Final Boundary Condition Loss\": bc_losses[-1],\n",
    "    \"Runtime Duration\": formatted_time\n",
    "}\n",
    "\n",
    "# Define the folder and file path\n",
    "parent_folder = os.path.abspath(os.path.join(os.getcwd(), os.pardir))  # Get the parent directory\n",
    "burgers_kan_folder = os.path.join(parent_folder, \"results\", \"HJB_KAN\")\n",
    "data_folder = os.path.join(burgers_kan_folder, \"data\")\n",
    "file_path = os.path.join(data_folder, \"data.json\")\n",
    "\n",
    "# Create the folders if they don't exist\n",
    "os.makedirs(data_folder, exist_ok=True)\n",
    "\n",
    "# Initialize data_list\n",
    "data_list = []\n",
    "\n",
    "# Check if the JSON file exists and is not empty\n",
    "if os.path.exists(file_path):\n",
    "    try:\n",
    "        with open(file_path, \"r\") as file:\n",
    "            # Attempt to read the existing data\n",
    "            data_list = json.load(file)\n",
    "    except json.JSONDecodeError:\n",
    "        # If there's an error, print a warning and continue with an empty list\n",
    "        print(\"Warning: data.json is empty or corrupted. Starting with an empty list.\")\n",
    "        data_list = []\n",
    "\n",
    "# Append the new data\n",
    "data_list.append(data)\n",
    "\n",
    "# Write the updated list of dictionaries back to the JSON file\n",
    "with open(file_path, \"w\") as file:\n",
    "    json.dump(data_list, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of losses and their names for plotting\n",
    "loss_lists = [int_losses, bc_losses]\n",
    "loss_names = [\"int_losses\", \"bc_losses\"]\n",
    "\n",
    "# Define the figure title\n",
    "figure_title = \"Training Losses\"\n",
    "\n",
    "# Create the subplots\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "fig.suptitle(figure_title, fontsize=20)\n",
    "\n",
    "# Plot each loss list\n",
    "for i, (loss_list, loss_name) in enumerate(zip(loss_lists, loss_names)):\n",
    "    axs[i].plot(loss_list, marker='o')\n",
    "    axs[i].set_xlabel(\"epoch/step\")\n",
    "    axs[i].set_ylabel(\"loss value\")\n",
    "    axs[i].set_title(loss_name)\n",
    "    axs[i].grid(True)\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "fig.tight_layout(rect=[0, 0, 1, 0.95])  # Leave space for the main title\n",
    "\n",
    "# Define the folder path in the parent directory\n",
    "parent_folder = os.path.abspath(os.path.join(os.getcwd(), os.pardir))  # Get the parent directory\n",
    "training_plots_folder = os.path.join(parent_folder, \"results\", \"HJB_KAN\", \"training_plots\")\n",
    "\n",
    "# Create the training_plots folder if it doesn't exist\n",
    "os.makedirs(training_plots_folder, exist_ok=True)\n",
    "\n",
    "# Join the elements of the array with underscores to create the file name\n",
    "file_name = \"_\".join(map(str, model_shape)) + f\"_HJB_{xdim}_{steps}\" + \".jpeg\"\n",
    "\n",
    "# Save the figure in the training_plots folder\n",
    "save_path = os.path.join(training_plots_folder, file_name)\n",
    "plt.savefig(save_path, format='jpeg')\n",
    "plt.close(fig)  # Close the figure to free up memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
